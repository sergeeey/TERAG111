"""
–ú–æ–¥—É–ª—å –∞–≥—Ä–µ–≥–∞—Ü–∏–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∞—É–¥–∏—Ç–∞
–°–æ–±–∏—Ä–∞–µ—Ç –≤—Å–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∞—É–¥–∏—Ç–∞ –≤ –µ–¥–∏–Ω—ã–π –æ—Ç—á—ë—Ç —Å –æ–±—â–∏–º–∏ –º–µ—Ç—Ä–∏–∫–∞–º–∏ –∏ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è–º–∏
"""

import json
import os
import sys
from datetime import datetime, timezone
from typing import Dict, List, Any, Optional
import glob

class AuditAggregator:
    """–ê–≥—Ä–µ–≥–∞—Ç–æ—Ä —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∞—É–¥–∏—Ç–∞"""
    
    def __init__(self, report_dir: str):
        self.report_dir = report_dir
        self.aggregated_results = {}
        
    def aggregate_all_results(self) -> Dict[str, Any]:
        """–ê–≥—Ä–µ–≥–∞—Ü–∏—è –≤—Å–µ—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∞—É–¥–∏—Ç–∞"""
        try:
            # –°–±–æ—Ä –≤—Å–µ—Ö JSON –æ—Ç—á—ë—Ç–æ–≤
            json_files = glob.glob(os.path.join(self.report_dir, "**/*.json"), recursive=True)
            
            # –ó–∞–≥—Ä—É–∑–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
            results = {}
            for json_file in json_files:
                try:
                    with open(json_file, 'r', encoding='utf-8') as f:
                        data = json.load(f)
                    filename = os.path.basename(json_file).replace('.json', '')
                    results[filename] = data
                except Exception as e:
                    print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ {json_file}: {e}")
            
            # –ê–≥—Ä–µ–≥–∞—Ü–∏—è –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º
            aggregated = {
                "metadata": self._create_metadata(),
                "cognitive_audit": self._aggregate_cognitive_results(results),
                "observability_audit": self._aggregate_observability_results(results),
                "ethics_audit": self._aggregate_ethics_results(results),
                "governance_audit": self._aggregate_governance_results(results),
                "environment_audit": self._aggregate_environment_results(results),
                "architecture_audit": self._aggregate_architecture_results(results),
                "technical_audit": self._aggregate_technical_results(results),
                "overall_assessment": self._calculate_overall_assessment(results)
            }
            
            return aggregated
            
        except Exception as e:
            return {
                "error": str(e),
                "timestamp": datetime.now(timezone.utc).isoformat(),
                "status": "failed"
            }
    
    def _create_metadata(self) -> Dict[str, Any]:
        """–°–æ–∑–¥–∞–Ω–∏–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö –∞—É–¥–∏—Ç–∞"""
        return {
            "audit_timestamp": datetime.now(timezone.utc).isoformat(),
            "audit_version": "1.2",
            "project_name": "TERAG-AI-REPS",
            "report_directory": self.report_dir,
            "aggregation_method": "weighted_average"
        }
    
    def _aggregate_cognitive_results(self, results: Dict[str, Any]) -> Dict[str, Any]:
        """–ê–≥—Ä–µ–≥–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∫–æ–≥–Ω–∏—Ç–∏–≤–Ω–æ–≥–æ –∞—É–¥–∏—Ç–∞"""
        cognitive_data = results.get('cognitive_metrics', {})
        
        if 'error' in cognitive_data:
            return {
                "status": "failed",
                "error": cognitive_data['error'],
                "score": 0.0
            }
        
        cognitive_scores = cognitive_data.get('cognitive_scores', {})
        current_metrics = cognitive_data.get('current_metrics', {})
        health_status = cognitive_data.get('health_status', {})
        
        return {
            "status": "completed",
            "overall_cognitive_health": cognitive_scores.get('overall_cognitive_health', 0.0),
            "stability_score": cognitive_scores.get('stability_score', 0.0),
            "coherence_score": cognitive_scores.get('coherence_score', 0.0),
            "current_metrics": current_metrics,
            "health_status": health_status.get('status', 'unknown'),
            "phase_drift": health_status.get('resonance_phase_drift', 0.0),
            "compliance": cognitive_data.get('compliance', {}),
            "recommendations": self._extract_cognitive_recommendations(cognitive_data)
        }
    
    def _aggregate_observability_results(self, results: Dict[str, Any]) -> Dict[str, Any]:
        """–ê–≥—Ä–µ–≥–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∞—É–¥–∏—Ç–∞ –Ω–∞–±–ª—é–¥–∞–µ–º–æ—Å—Ç–∏"""
        observability_data = results.get('observability', {})
        drift_data = results.get('drift_analysis', {})
        
        if 'error' in observability_data:
            return {
                "status": "failed",
                "error": observability_data['error'],
                "score": 0.0
            }
        
        return {
            "status": "completed",
            "observability_score": observability_data.get('observability_score', 0.0),
            "overall_drift_index": drift_data.get('overall_drift_index', 0.0),
            "drift_status": drift_data.get('drift_status', 'unknown'),
            "anomalies_count": len(drift_data.get('anomalies', [])),
            "trends": drift_data.get('trends', {}),
            "recommendations": self._extract_observability_recommendations(observability_data, drift_data)
        }
    
    def _aggregate_ethics_results(self, results: Dict[str, Any]) -> Dict[str, Any]:
        """–ê–≥—Ä–µ–≥–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ —ç—Ç–∏—á–µ—Å–∫–æ–≥–æ –∞—É–¥–∏—Ç–∞"""
        ethics_data = results.get('ethics_audit', {})
        
        if 'error' in ethics_data:
            return {
                "status": "failed",
                "error": ethics_data['error'],
                "score": 0.0
            }
        
        return {
            "status": "completed",
            "overall_ethical_score": ethics_data.get('overall_ethical_score', 0.0),
            "ethical_status": ethics_data.get('ethical_status', 'unknown'),
            "documentation_score": ethics_data.get('documentation_audit', {}).get('documentation_score', 0.0),
            "code_ethics_score": ethics_data.get('code_audit', {}).get('overall_code_ethics_score', 0.0),
            "privacy_score": self._calculate_privacy_score(ethics_data.get('privacy_audit', {})),
            "recommendations": ethics_data.get('recommendations', [])
        }
    
    def _aggregate_environment_results(self, results: Dict[str, Any]) -> Dict[str, Any]:
        """–ê–≥—Ä–µ–≥–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ environment-–∞—É–¥–∏—Ç–∞"""
        env_data = results.get('cursor_env', {})
        
        if 'error' in env_data:
            return {
                "status": "failed",
                "error": env_data['error'],
                "score": 0.0
            }
        
        return {
            "status": "completed",
            "environment_score": env_data.get('environment_score', 0.0),
            "environment_status": env_data.get('status', 'unknown'),
            "total_issues": env_data.get('total_issues', 0),
            "total_recommendations": env_data.get('total_recommendations', 0),
            "workspace_consistency": env_data.get('checks', {}).get('workspace_consistency', {}),
            "mcp_integrations": env_data.get('checks', {}).get('mcp_integrations', {}),
            "project_structure": env_data.get('checks', {}).get('project_structure', {}),
            "recommendations": env_data.get('all_recommendations', [])
        }
    
    def _aggregate_architecture_results(self, results: Dict[str, Any]) -> Dict[str, Any]:
        """–ê–≥—Ä–µ–≥–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–Ω–æ–≥–æ –∞—É–¥–∏—Ç–∞"""
        arch_data = results.get('architecture_audit', {})
        
        if 'error' in arch_data:
            return {
                "status": "failed",
                "error": arch_data['error'],
                "score": 0.0
            }
        
        return {
            "status": "completed",
            "architecture_score": arch_data.get('architecture_score', 0.0),
            "sections_found": arch_data.get('sections_found', 0),
            "sections_expected": arch_data.get('sections_expected', 0),
            "total_modules": arch_data.get('total_modules', 0),
            "code_analysis": arch_data.get('code_analysis', {}),
            "component_coverage": arch_data.get('component_coverage', {}),
            "issues": arch_data.get('issues', []),
            "recommendations": arch_data.get('recommendations', [])
        }
    
    def _aggregate_governance_results(self, results: Dict[str, Any]) -> Dict[str, Any]:
        """–ê–≥—Ä–µ–≥–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ —É–ø—Ä–∞–≤–ª–µ–Ω—á–µ—Å–∫–æ–≥–æ –∞—É–¥–∏—Ç–∞"""
        governance_data = results.get('governance_audit', {})
        
        if 'error' in governance_data:
            return {
                "status": "failed",
                "error": governance_data['error'],
                "score": 0.0
            }
        
        return {
            "status": "completed",
            "overall_governance_score": governance_data.get('overall_governance_score', 0.0),
            "governance_status": governance_data.get('governance_status', 'unknown'),
            "mission_alignment": governance_data.get('mission_audit', {}).get('alignment_score', 0.0),
            "policy_coverage": governance_data.get('policies_audit', {}).get('policy_coverage', 0.0),
            "compliance_score": governance_data.get('compliance_audit', {}).get('compliance_score', 0.0),
            "continuity_score": governance_data.get('continuity_audit', {}).get('continuity_score', 0.0),
            "recommendations": governance_data.get('recommendations', [])
        }
    
    def _aggregate_technical_results(self, results: Dict[str, Any]) -> Dict[str, Any]:
        """–ê–≥—Ä–µ–≥–∞—Ü–∏—è —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∞—É–¥–∏—Ç–∞"""
        technical_results = {
            "code_quality": self._analyze_code_quality(results),
            "security": self._analyze_security(results),
            "performance": self._analyze_performance(results),
            "coverage": self._analyze_coverage(results)
        }
        
        return technical_results
    
    def _analyze_code_quality(self, results: Dict[str, Any]) -> Dict[str, Any]:
        """–ê–Ω–∞–ª–∏–∑ –∫–∞—á–µ—Å—Ç–≤–∞ –∫–æ–¥–∞"""
        pylint_data = results.get('pylint', {})
        flake8_data = results.get('flake8', {})
        
        return {
            "pylint_score": self._extract_pylint_score(pylint_data),
            "flake8_issues": self._count_flake8_issues(flake8_data),
            "overall_quality": "good" if self._extract_pylint_score(pylint_data) > 7.0 else "needs_improvement"
        }
    
    def _analyze_security(self, results: Dict[str, Any]) -> Dict[str, Any]:
        """–ê–Ω–∞–ª–∏–∑ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏"""
        bandit_data = results.get('bandit', {})
        safety_data = results.get('safety', {})
        
        return {
            "bandit_issues": self._count_bandit_issues(bandit_data),
            "safety_issues": self._count_safety_issues(safety_data),
            "security_level": self._assess_security_level(bandit_data, safety_data)
        }
    
    def _analyze_performance(self, results: Dict[str, Any]) -> Dict[str, Any]:
        """–ê–Ω–∞–ª–∏–∑ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏"""
        perf_data = results.get('performance', {})
        
        return {
            "benchmarks_available": len(perf_data) > 0,
            "performance_data": perf_data,
            "performance_level": "good" if len(perf_data) > 0 else "unknown"
        }
    
    def _analyze_coverage(self, results: Dict[str, Any]) -> Dict[str, Any]:
        """–ê–Ω–∞–ª–∏–∑ –ø–æ–∫—Ä—ã—Ç–∏—è –∫–æ–¥–∞"""
        coverage_data = results.get('coverage', {})
        
        return {
            "coverage_available": len(coverage_data) > 0,
            "coverage_data": coverage_data,
            "coverage_level": "good" if len(coverage_data) > 0 else "unknown"
        }
    
    def _calculate_overall_assessment(self, results: Dict[str, Any]) -> Dict[str, Any]:
        """–†–∞—Å—á—ë—Ç –æ–±—â–µ–π –æ—Ü–µ–Ω–∫–∏ —Å–∏—Å—Ç–µ–º—ã"""
        # –í–µ—Å–∞ –¥–ª—è —Ä–∞–∑–Ω—ã—Ö –∞—Å–ø–µ–∫—Ç–æ–≤
        weights = {
            'cognitive': 0.2,
            'observability': 0.15,
            'ethics': 0.15,
            'governance': 0.15,
            'environment': 0.15,
            'architecture': 0.15,
            'technical': 0.05
        }
        
        # –°–±–æ—Ä –æ—Ü–µ–Ω–æ–∫
        scores = {}
        
        # –ö–æ–≥–Ω–∏—Ç–∏–≤–Ω–∞—è –æ—Ü–µ–Ω–∫–∞
        cognitive_data = results.get('cognitive_metrics', {})
        if 'error' not in cognitive_data:
            scores['cognitive'] = cognitive_data.get('cognitive_scores', {}).get('overall_cognitive_health', 0.0)
        else:
            scores['cognitive'] = 0.0
        
        # –û—Ü–µ–Ω–∫–∞ –Ω–∞–±–ª—é–¥–∞–µ–º–æ—Å—Ç–∏
        observability_data = results.get('observability', {})
        if 'error' not in observability_data:
            scores['observability'] = observability_data.get('observability_score', 0.0)
        else:
            scores['observability'] = 0.0
        
        # –≠—Ç–∏—á–µ—Å–∫–∞—è –æ—Ü–µ–Ω–∫–∞
        ethics_data = results.get('ethics_audit', {})
        if 'error' not in ethics_data:
            scores['ethics'] = ethics_data.get('overall_ethical_score', 0.0)
        else:
            scores['ethics'] = 0.0
        
        # –£–ø—Ä–∞–≤–ª–µ–Ω—á–µ—Å–∫–∞—è –æ—Ü–µ–Ω–∫–∞
        governance_data = results.get('governance_audit', {})
        if 'error' not in governance_data:
            scores['governance'] = governance_data.get('overall_governance_score', 0.0)
        else:
            scores['governance'] = 0.0
        
        # Environment-–æ—Ü–µ–Ω–∫–∞
        env_data = results.get('cursor_env', {})
        if 'error' not in env_data:
            scores['environment'] = env_data.get('environment_score', 0.0)
        else:
            scores['environment'] = 0.0
        
        # –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–Ω–∞—è –æ—Ü–µ–Ω–∫–∞
        arch_data = results.get('architecture_audit', {})
        if 'error' not in arch_data:
            scores['architecture'] = arch_data.get('architecture_score', 0.0)
        else:
            scores['architecture'] = 0.0
        
        # –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∞—è –æ—Ü–µ–Ω–∫–∞ (—É–ø—Ä–æ—â—ë–Ω–Ω–∞—è)
        technical_score = 0.5  # –ë–∞–∑–æ–≤—ã–π –±–∞–ª–ª
        if results.get('pylint'):
            technical_score += 0.2
        if results.get('bandit'):
            technical_score += 0.2
        if results.get('coverage'):
            technical_score += 0.1
        scores['technical'] = min(technical_score, 1.0)
        
        # –í–∑–≤–µ—à–µ–Ω–Ω–∞—è —Å—É–º–º–∞
        overall_score = sum(scores[aspect] * weights[aspect] for aspect in weights)
        
        # –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è —Å—Ç–∞—Ç—É—Å–∞
        if overall_score >= 0.8:
            status = "excellent"
            status_icon = "üü¢"
        elif overall_score >= 0.6:
            status = "good"
            status_icon = "üü°"
        elif overall_score >= 0.4:
            status = "fair"
            status_icon = "üü†"
        else:
            status = "poor"
            status_icon = "üî¥"
        
        return {
            "overall_score": overall_score,
            "status": status,
            "status_icon": status_icon,
            "component_scores": scores,
            "weights": weights,
            "recommendations": self._generate_overall_recommendations(scores, overall_score)
        }
    
    def _generate_overall_recommendations(self, scores: Dict[str, float], overall_score: float) -> List[str]:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ–±—â–∏—Ö —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π"""
        recommendations = []
        
        # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞–º —Å –Ω–∏–∑–∫–∏–º–∏ –æ—Ü–µ–Ω–∫–∞–º–∏
        for component, score in scores.items():
            if score < 0.5:
                if component == 'cognitive':
                    recommendations.append("üß† –£–ª—É—á—à–∏—Ç–µ –∫–æ–≥–Ω–∏—Ç–∏–≤–Ω—É—é —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å: –æ–ø—Ç–∏–º–∏–∑–∏—Ä—É–π—Ç–µ –º–µ—Ç—Ä–∏–∫–∏ RSS/COS/FAITH")
                elif component == 'observability':
                    recommendations.append("üëÅÔ∏è –£–ª—É—á—à–∏—Ç–µ –Ω–∞–±–ª—é–¥–∞–µ–º–æ—Å—Ç—å: –¥–æ–±–∞–≤—å—Ç–µ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –∏ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ")
                elif component == 'ethics':
                    recommendations.append("‚öñÔ∏è –£–ª—É—á—à–∏—Ç–µ —ç—Ç–∏—á–µ—Å–∫–æ–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ: –¥–æ–±–∞–≤—å—Ç–µ –ø–æ–ª–∏—Ç–∏–∫–∏ –∏ –ø—Ä–æ—Ü–µ–¥—É—Ä—ã")
                elif component == 'governance':
                    recommendations.append("üèõÔ∏è –£–ª—É—á—à–∏—Ç–µ —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ: –æ–ø—Ä–µ–¥–µ–ª–∏—Ç–µ —Ä–æ–ª–∏ –∏ –ø—Ä–æ—Ü–µ—Å—Å—ã")
                elif component == 'technical':
                    recommendations.append("üîß –£–ª—É—á—à–∏—Ç–µ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ: –∏—Å–ø—Ä–∞–≤—å—Ç–µ –æ—à–∏–±–∫–∏ –∫–æ–¥–∞ –∏ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏")
        
        # –û–±—â–∏–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
        if overall_score < 0.6:
            recommendations.append("üö® –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏–π —É—Ä–æ–≤–µ–Ω—å: —Ç—Ä–µ–±—É–µ—Ç—Å—è –∫–æ–º–ø–ª–µ–∫—Å–Ω–∞—è —Ä–µ—Å—Ç—Ä—É–∫—Ç—É—Ä–∏–∑–∞—Ü–∏—è —Å–∏—Å—Ç–µ–º—ã")
        elif overall_score < 0.8:
            recommendations.append("‚ö†Ô∏è –£–º–µ—Ä–µ–Ω–Ω—ã–π —É—Ä–æ–≤–µ–Ω—å: –ø—Ä–æ–¥–æ–ª–∂–∞–π—Ç–µ —É–ª—É—á—à–µ–Ω–∏—è –ø–æ –≤—Å–µ–º –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏—è–º")
        else:
            recommendations.append("‚úÖ –û—Ç–ª–∏—á–Ω—ã–π —É—Ä–æ–≤–µ–Ω—å: –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–π—Ç–µ —Ç–µ–∫—É—â–µ–µ –∫–∞—á–µ—Å—Ç–≤–æ –∏ –ø—Ä–æ–¥–æ–ª–∂–∞–π—Ç–µ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥")
        
        return recommendations
    
    def _extract_cognitive_recommendations(self, cognitive_data: Dict) -> List[str]:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –∏–∑ –∫–æ–≥–Ω–∏—Ç–∏–≤–Ω–æ–≥–æ –∞—É–¥–∏—Ç–∞"""
        # –ü—Ä–æ—Å—Ç—ã–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –º–µ—Ç—Ä–∏–∫
        recommendations = []
        
        current_metrics = cognitive_data.get('current_metrics', {})
        if current_metrics.get('RSS', 0) < 0.8:
            recommendations.append("üìä –£–ª—É—á—à–∏—Ç–µ RSS: –æ–ø—Ç–∏–º–∏–∑–∏—Ä—É–π—Ç–µ —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–π")
        if current_metrics.get('Resonance', 0) < 0.85:
            recommendations.append("üîÑ –£–ª—É—á—à–∏—Ç–µ Resonance: —Å—Ç–∞–±–∏–ª–∏–∑–∏—Ä—É–π—Ç–µ —Ñ–∞–∑–æ–≤—ã–π —Ä–µ–∑–æ–Ω–∞–Ω—Å")
        
        return recommendations
    
    def _extract_observability_recommendations(self, observability_data: Dict, drift_data: Dict) -> List[str]:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –∏–∑ –∞—É–¥–∏—Ç–∞ –Ω–∞–±–ª—é–¥–∞–µ–º–æ—Å—Ç–∏"""
        recommendations = []
        
        if observability_data.get('observability_score', 0) < 0.6:
            recommendations.append("üëÅÔ∏è –£–ª—É—á—à–∏—Ç–µ –Ω–∞–±–ª—é–¥–∞–µ–º–æ—Å—Ç—å —Å–∏—Å—Ç–µ–º—ã")
        
        if drift_data.get('overall_drift_index', 0) > 0.3:
            recommendations.append("üìà –í—ã—Å–æ–∫–∏–π –¥—Ä–µ–π—Ñ: —Å—Ç–∞–±–∏–ª–∏–∑–∏—Ä—É–π—Ç–µ –ø–æ–≤–µ–¥–µ–Ω–∏–µ —Å–∏—Å—Ç–µ–º—ã")
        
        return recommendations
    
    def _calculate_privacy_score(self, privacy_audit: Dict) -> float:
        """–†–∞—Å—á—ë—Ç –æ—Ü–µ–Ω–∫–∏ –ø—Ä–∏–≤–∞—Ç–Ω–æ—Å—Ç–∏"""
        if not privacy_audit:
            return 0.0
        
        scores = []
        
        # –û—Ü–µ–Ω–∫–∞ —Å–±–æ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö
        data_collection = privacy_audit.get('data_collection', {})
        if data_collection.get('minimal_collection') and data_collection.get('purpose_limitation'):
            scores.append(0.8)
        else:
            scores.append(0.4)
        
        # –û—Ü–µ–Ω–∫–∞ —Ö—Ä–∞–Ω–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö
        data_storage = privacy_audit.get('data_storage', {})
        if data_storage.get('local_storage') and data_storage.get('retention_policy'):
            scores.append(0.6)
        else:
            scores.append(0.3)
        
        return sum(scores) / len(scores) if scores else 0.0
    
    def _extract_pylint_score(self, pylint_data: Dict) -> float:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –æ—Ü–µ–Ω–∫–∏ Pylint"""
        if not pylint_data or not isinstance(pylint_data, list):
            return 0.0
        
        # –ü–æ–∏—Å–∫ –æ—Ü–µ–Ω–∫–∏ –≤ –¥–∞–Ω–Ω—ã—Ö Pylint
        for item in pylint_data:
            if isinstance(item, dict) and 'score' in item:
                return float(item['score'])
        
        return 0.0
    
    def _count_flake8_issues(self, flake8_data: Dict) -> int:
        """–ü–æ–¥—Å—á—ë—Ç –ø—Ä–æ–±–ª–µ–º Flake8"""
        if not flake8_data or not isinstance(flake8_data, list):
            return 0
        
        return len(flake8_data)
    
    def _count_bandit_issues(self, bandit_data: Dict) -> int:
        """–ü–æ–¥—Å—á—ë—Ç –ø—Ä–æ–±–ª–µ–º Bandit"""
        if not bandit_data or not isinstance(bandit_data, dict):
            return 0
        
        results = bandit_data.get('results', [])
        return len(results) if isinstance(results, list) else 0
    
    def _count_safety_issues(self, safety_data: Dict) -> int:
        """–ü–æ–¥—Å—á—ë—Ç –ø—Ä–æ–±–ª–µ–º Safety"""
        if not safety_data or not isinstance(safety_data, list):
            return 0
        
        return len(safety_data)
    
    def _assess_security_level(self, bandit_data: Dict, safety_data: Dict) -> str:
        """–û—Ü–µ–Ω–∫–∞ —É—Ä–æ–≤–Ω—è –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏"""
        bandit_issues = self._count_bandit_issues(bandit_data)
        safety_issues = self._count_safety_issues(safety_data)
        
        total_issues = bandit_issues + safety_issues
        
        if total_issues == 0:
            return "excellent"
        elif total_issues <= 5:
            return "good"
        elif total_issues <= 10:
            return "fair"
        else:
            return "poor"
    
    def generate_final_report(self, output_path: str = None) -> str:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ –æ—Ç—á—ë—Ç–∞"""
        aggregated = self.aggregate_all_results()
        
        if 'error' in aggregated:
            report = f"# ‚ùå –û—à–∏–±–∫–∞ –∞–≥—Ä–µ–≥–∞—Ü–∏–∏ –∞—É–¥–∏—Ç–∞\n\n{aggregated['error']}"
        else:
            overall = aggregated['overall_assessment']
            
            report = f"""# üß≠ Auditor CurSor v1.2 - –§–∏–Ω–∞–ª—å–Ω—ã–π –æ—Ç—á—ë—Ç –∞—É–¥–∏—Ç–∞

**–ü—Ä–æ–µ–∫—Ç:** TERAG AI-REPS  
**–í—Ä–µ–º—è –∞—É–¥–∏—Ç–∞:** {aggregated['metadata']['audit_timestamp']}  
**–û–±—â–∞—è –æ—Ü–µ–Ω–∫–∞:** {overall['status_icon']} {overall['overall_score']:.3f} ({overall['status']})  

## üìä –°–≤–æ–¥–∫–∞ –ø–æ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞–º

### üß† –ö–æ–≥–Ω–∏—Ç–∏–≤–Ω—ã–π –∞—É–¥–∏—Ç
- **–°—Ç–∞—Ç—É—Å:** {'‚úÖ' if aggregated['cognitive_audit']['status'] == 'completed' else '‚ùå'}
- **–û–±—â–µ–µ –∑–¥–æ—Ä–æ–≤—å–µ:** {aggregated['cognitive_audit']['overall_cognitive_health']:.3f}
- **–°—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å:** {aggregated['cognitive_audit']['stability_score']:.3f}
- **–ö–æ–≥–µ—Ä–µ–Ω—Ç–Ω–æ—Å—Ç—å:** {aggregated['cognitive_audit']['coherence_score']:.3f}

### üëÅÔ∏è –ù–∞–±–ª—é–¥–∞–µ–º–æ—Å—Ç—å
- **–°—Ç–∞—Ç—É—Å:** {'‚úÖ' if aggregated['observability_audit']['status'] == 'completed' else '‚ùå'}
- **–û—Ü–µ–Ω–∫–∞ –Ω–∞–±–ª—é–¥–∞–µ–º–æ—Å—Ç–∏:** {aggregated['observability_audit']['observability_score']:.3f}
- **–ò–Ω–¥–µ–∫—Å –¥—Ä–µ–π—Ñ–∞:** {aggregated['observability_audit']['overall_drift_index']:.3f}
- **–ê–Ω–æ–º–∞–ª–∏–∏:** {aggregated['observability_audit']['anomalies_count']}

### ‚öñÔ∏è –≠—Ç–∏—á–µ—Å–∫–∏–π –∞—É–¥–∏—Ç
- **–°—Ç–∞—Ç—É—Å:** {'‚úÖ' if aggregated['ethics_audit']['status'] == 'completed' else '‚ùå'}
- **–≠—Ç–∏—á–µ—Å–∫–∞—è –æ—Ü–µ–Ω–∫–∞:** {aggregated['ethics_audit']['overall_ethical_score']:.3f}
- **–î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è:** {aggregated['ethics_audit']['documentation_score']:.3f}
- **–ö–æ–¥:** {aggregated['ethics_audit']['code_ethics_score']:.3f}

### üèõÔ∏è –£–ø—Ä–∞–≤–ª–µ–Ω—á–µ—Å–∫–∏–π –∞—É–¥–∏—Ç
- **–°—Ç–∞—Ç—É—Å:** {'‚úÖ' if aggregated['governance_audit']['status'] == 'completed' else '‚ùå'}
- **–£–ø—Ä–∞–≤–ª–µ–Ω—á–µ—Å–∫–∞—è –æ—Ü–µ–Ω–∫–∞:** {aggregated['governance_audit']['overall_governance_score']:.3f}
- **–í—ã—Ä–∞–≤–Ω–∏–≤–∞–Ω–∏–µ –º–∏—Å—Å–∏–∏:** {aggregated['governance_audit']['mission_alignment']:.3f}
- **–ü–æ–∫—Ä—ã—Ç–∏–µ –ø–æ–ª–∏—Ç–∏–∫:** {aggregated['governance_audit']['policy_coverage']:.3f}

### üîß Environment-–∞—É–¥–∏—Ç
- **–°—Ç–∞—Ç—É—Å:** {'‚úÖ' if aggregated['environment_audit']['status'] == 'completed' else '‚ùå'}
- **Environment-–æ—Ü–µ–Ω–∫–∞:** {aggregated['environment_audit']['environment_score']:.3f}
- **–ü—Ä–æ–±–ª–µ–º—ã –æ–∫—Ä—É–∂–µ–Ω–∏—è:** {aggregated['environment_audit']['total_issues']}
- **–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π:** {aggregated['environment_audit']['total_recommendations']}

### üß© Architecture-–∞—É–¥–∏—Ç
- **–°—Ç–∞—Ç—É—Å:** {'‚úÖ' if aggregated['architecture_audit']['status'] == 'completed' else '‚ùå'}
- **Architecture-–æ—Ü–µ–Ω–∫–∞:** {aggregated['architecture_audit']['architecture_score']:.3f}
- **–°–µ–∫—Ü–∏–π –Ω–∞–π–¥–µ–Ω–æ:** {aggregated['architecture_audit']['sections_found']}/{aggregated['architecture_audit']['sections_expected']}
- **–ú–æ–¥—É–ª–µ–π –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–æ:** {aggregated['architecture_audit']['total_modules']}
- **–ü—Ä–æ–±–ª–µ–º –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã:** {len(aggregated['architecture_audit']['issues'])}

### üîß –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–π –∞—É–¥–∏—Ç
- **–ö–∞—á–µ—Å—Ç–≤–æ –∫–æ–¥–∞:** {aggregated['technical_audit']['code_quality']['overall_quality']}
- **–ë–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å:** {aggregated['technical_audit']['security']['security_level']}
- **–ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å:** {aggregated['technical_audit']['performance']['performance_level']}
- **–ü–æ–∫—Ä—ã—Ç–∏–µ:** {aggregated['technical_audit']['coverage']['coverage_level']}

## üéØ –ö–ª—é—á–µ–≤—ã–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏

"""
            
            for i, rec in enumerate(overall['recommendations'], 1):
                report += f"{i}. {rec}\n"
            
            report += f"""

## üìà –î–µ—Ç–∞–ª—å–Ω—ã–µ –æ—Ü–µ–Ω–∫–∏ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤

"""
            
            for component, score in overall['component_scores'].items():
                icon = "üü¢" if score >= 0.8 else "üü°" if score >= 0.6 else "üü†" if score >= 0.4 else "üî¥"
                report += f"- {icon} **{component.title()}:** {score:.3f}\n"
        
        if output_path:
            with open(output_path, 'w', encoding='utf-8') as f:
                f.write(report)
        
        return report

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –∑–∞–ø—É—Å–∫–∞ –∞–≥—Ä–µ–≥–∞—Ü–∏–∏"""
    import argparse
    
    parser = argparse.ArgumentParser(description='–ê–≥—Ä–µ–≥–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∞—É–¥–∏—Ç–∞ TERAG AI-REPS')
    parser.add_argument('report_dir', help='–î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è —Å –æ—Ç—á—ë—Ç–∞–º–∏ –∞—É–¥–∏—Ç–∞')
    parser.add_argument('--output', '-o', help='–ü—É—Ç—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ –æ—Ç—á—ë—Ç–∞')
    
    args = parser.parse_args()
    
    aggregator = AuditAggregator(args.report_dir)
    report = aggregator.generate_final_report(args.output)
    
    if not args.output:
        print(report)

if __name__ == "__main__":
    main()
