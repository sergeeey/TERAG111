"""
–ú–æ–¥—É–ª—å —ç—Ç–∏—á–µ—Å–∫–æ–≥–æ –∞—É–¥–∏—Ç–∞ AI-—Å–∏—Å—Ç–µ–º
–ü—Ä–æ–≤–µ—Ä—è–µ—Ç —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ —ç—Ç–∏—á–µ—Å–∫–∏–º –ø—Ä–∏–Ω—Ü–∏–ø–∞–º, —Å–ø—Ä–∞–≤–µ–¥–ª–∏–≤–æ—Å—Ç–∏ –∏ –ø—Ä–æ–∑—Ä–∞—á–Ω–æ—Å—Ç–∏
"""

import json
import os
import sys
from datetime import datetime, timezone
from typing import Dict, List, Any, Optional
import re

class EthicsAuditor:
    """–ê—É–¥–∏—Ç–æ—Ä —ç—Ç–∏—á–µ—Å–∫–∏—Ö –∞—Å–ø–µ–∫—Ç–æ–≤ AI-—Å–∏—Å—Ç–µ–º"""
    
    def __init__(self, config_path: str = ".auditconfig.yaml"):
        self.config = self._load_config(config_path)
        self.ethical_principles = [
            "fairness", "transparency", "accountability", "privacy", 
            "safety", "human_autonomy", "non_maleficence", "beneficence"
        ]
        
    def _load_config(self, config_path: str) -> Dict:
        """–ó–∞–≥—Ä—É–∑–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏"""
        try:
            import yaml
            with open(config_path, 'r', encoding='utf-8') as f:
                return yaml.safe_load(f)
        except Exception as e:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏: {e}")
            return {}
    
    def evaluate_ethical_compliance(self) -> Dict[str, Any]:
        """–û—Ü–µ–Ω–∫–∞ —ç—Ç–∏—á–µ—Å–∫–æ–≥–æ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è —Å–∏—Å—Ç–µ–º—ã"""
        try:
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏
            documentation_audit = self._audit_documentation()
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–æ–¥–∞ –Ω–∞ —ç—Ç–∏—á–µ—Å–∫–∏–µ –∞—Å–ø–µ–∫—Ç—ã
            code_audit = self._audit_code_ethics()
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
            config_audit = self._audit_configuration()
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∏ –ø—Ä–∏–≤–∞—Ç–Ω–æ—Å—Ç–∏
            privacy_audit = self._audit_privacy()
            
            # –û–±—â–∞—è –æ—Ü–µ–Ω–∫–∞
            overall_score = self._calculate_ethical_score(
                documentation_audit, code_audit, config_audit, privacy_audit
            )
            
            return {
                "timestamp": datetime.now(timezone.utc).isoformat(),
                "overall_ethical_score": overall_score,
                "documentation_audit": documentation_audit,
                "code_audit": code_audit,
                "config_audit": config_audit,
                "privacy_audit": privacy_audit,
                "ethical_status": self._classify_ethical_status(overall_score),
                "recommendations": self._generate_ethical_recommendations(
                    documentation_audit, code_audit, config_audit, privacy_audit
                )
            }
            
        except Exception as e:
            return {
                "error": str(e),
                "timestamp": datetime.now(timezone.utc).isoformat(),
                "status": "failed"
            }
    
    def _audit_documentation(self) -> Dict[str, Any]:
        """–ê—É–¥–∏—Ç —ç—Ç–∏—á–µ—Å–∫–æ–π –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏"""
        ethical_docs = []
        missing_docs = []
        
        # –°–ø–∏—Å–æ–∫ –≤–∞–∂–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
        important_docs = [
            "README.md", "SECURITY.md", "AUDIT_SPEC.md", 
            "docs/ethics/", "docs/governance/", "CHANGELOG.md"
        ]
        
        for doc in important_docs:
            if os.path.exists(doc):
                ethical_docs.append(doc)
            else:
                missing_docs.append(doc)
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏—è README –Ω–∞ —ç—Ç–∏—á–µ—Å–∫–∏–µ –∞—Å–ø–µ–∫—Ç—ã
        readme_ethics_score = 0.0
        if os.path.exists("README.md"):
            readme_ethics_score = self._analyze_readme_ethics("README.md")
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è –ø–æ–ª–∏—Ç–∏–∫
        policies = self._check_ethical_policies()
        
        return {
            "documentation_score": len(ethical_docs) / len(important_docs),
            "present_docs": ethical_docs,
            "missing_docs": missing_docs,
            "readme_ethics_score": readme_ethics_score,
            "policies": policies
        }
    
    def _analyze_readme_ethics(self, readme_path: str) -> float:
        """–ê–Ω–∞–ª–∏–∑ —ç—Ç–∏—á–µ—Å–∫–∏—Ö –∞—Å–ø–µ–∫—Ç–æ–≤ –≤ README"""
        try:
            with open(readme_path, 'r', encoding='utf-8') as f:
                content = f.read().lower()
            
            ethical_keywords = [
                "ethics", "ethical", "fairness", "bias", "transparency",
                "privacy", "security", "safety", "accountability", "governance",
                "responsible", "trust", "explainable", "audit", "compliance"
            ]
            
            found_keywords = sum(1 for keyword in ethical_keywords if keyword in content)
            return min(found_keywords / len(ethical_keywords), 1.0)
            
        except Exception:
            return 0.0
    
    def _check_ethical_policies(self) -> Dict[str, bool]:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è —ç—Ç–∏—á–µ—Å–∫–∏—Ö –ø–æ–ª–∏—Ç–∏–∫"""
        policies = {
            "privacy_policy": False,
            "bias_mitigation": False,
            "transparency_policy": False,
            "safety_guidelines": False,
            "audit_procedures": False
        }
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –≤ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –∞—É–¥–∏—Ç–∞
        if self.config.get('governance_audit', {}).get('enabled'):
            policies["audit_procedures"] = True
        
        if self.config.get('security_audit', {}).get('enabled'):
            policies["safety_guidelines"] = True
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –≤ –∫–æ–¥–µ –Ω–∞ —É–ø–æ–º–∏–Ω–∞–Ω–∏—è —ç—Ç–∏—á–µ—Å–∫–∏—Ö –∞—Å–ø–µ–∫—Ç–æ–≤
        code_ethics = self._scan_code_for_ethics()
        if code_ethics.get('privacy_mentions', 0) > 0:
            policies["privacy_policy"] = True
        if code_ethics.get('bias_mentions', 0) > 0:
            policies["bias_mitigation"] = True
        if code_ethics.get('transparency_mentions', 0) > 0:
            policies["transparency_policy"] = True
        
        return policies
    
    def _scan_code_for_ethics(self) -> Dict[str, int]:
        """–°–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–æ–¥–∞ –Ω–∞ —É–ø–æ–º–∏–Ω–∞–Ω–∏—è —ç—Ç–∏—á–µ—Å–∫–∏—Ö –∞—Å–ø–µ–∫—Ç–æ–≤"""
        ethics_counts = {
            "privacy_mentions": 0,
            "bias_mentions": 0,
            "transparency_mentions": 0,
            "safety_mentions": 0
        }
        
        # –ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –¥–ª—è –ø–æ–∏—Å–∫–∞
        privacy_keywords = ["privacy", "personal_data", "gdpr", "pii", "confidential"]
        bias_keywords = ["bias", "fairness", "discrimination", "equity", "unbiased"]
        transparency_keywords = ["transparent", "explainable", "interpretable", "audit", "log"]
        safety_keywords = ["safety", "secure", "validation", "sanitize", "escape"]
        
        # –°–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ —Ñ–∞–π–ª–æ–≤
        source_dirs = self.config.get('source_dirs', ['src/'])
        for source_dir in source_dirs:
            if os.path.exists(source_dir):
                for root, dirs, files in os.walk(source_dir):
                    for file in files:
                        if file.endswith(('.py', '.ts', '.tsx', '.js', '.jsx')):
                            file_path = os.path.join(root, file)
                            try:
                                with open(file_path, 'r', encoding='utf-8') as f:
                                    content = f.read().lower()
                                
                                ethics_counts["privacy_mentions"] += sum(1 for kw in privacy_keywords if kw in content)
                                ethics_counts["bias_mentions"] += sum(1 for kw in bias_keywords if kw in content)
                                ethics_counts["transparency_mentions"] += sum(1 for kw in transparency_keywords if kw in content)
                                ethics_counts["safety_mentions"] += sum(1 for kw in safety_keywords if kw in content)
                                
                            except Exception:
                                continue
        
        return ethics_counts
    
    def _audit_code_ethics(self) -> Dict[str, Any]:
        """–ê—É–¥–∏—Ç —ç—Ç–∏—á–µ—Å–∫–∏—Ö –∞—Å–ø–µ–∫—Ç–æ–≤ –≤ –∫–æ–¥–µ"""
        code_ethics = self._scan_code_for_ethics()
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω–æ –ø—Ä–æ–±–ª–µ–º–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã
        problematic_patterns = self._check_problematic_patterns()
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å –¥–∞–Ω–Ω—ã—Ö
        data_safety = self._check_data_safety()
        
        return {
            "ethics_mentions": code_ethics,
            "problematic_patterns": problematic_patterns,
            "data_safety": data_safety,
            "overall_code_ethics_score": self._calculate_code_ethics_score(code_ethics, problematic_patterns, data_safety)
        }
    
    def _check_problematic_patterns(self) -> Dict[str, List[str]]:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –ø—Ä–æ–±–ª–µ–º–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã –≤ –∫–æ–¥–µ"""
        patterns = {
            "hardcoded_secrets": [],
            "unsafe_eval": [],
            "sql_injection_risk": [],
            "xss_risk": []
        }
        
        source_dirs = self.config.get('source_dirs', ['src/'])
        for source_dir in source_dirs:
            if os.path.exists(source_dir):
                for root, dirs, files in os.walk(source_dir):
                    for file in files:
                        if file.endswith(('.py', '.ts', '.tsx', '.js', '.jsx')):
                            file_path = os.path.join(root, file)
                            try:
                                with open(file_path, 'r', encoding='utf-8') as f:
                                    content = f.read()
                                
                                # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ —Ö–∞—Ä–¥–∫–æ–¥ —Å–µ–∫—Ä–µ—Ç–æ–≤
                                if re.search(r'(password|secret|key|token)\s*=\s*["\'][^"\']+["\']', content, re.IGNORECASE):
                                    patterns["hardcoded_secrets"].append(file_path)
                                
                                # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –Ω–µ–±–µ–∑–æ–ø–∞—Å–Ω—ã–π eval
                                if 'eval(' in content:
                                    patterns["unsafe_eval"].append(file_path)
                                
                                # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ SQL –∏–Ω—ä–µ–∫—Ü–∏–∏
                                if re.search(r'execute\s*\(\s*["\'].*\+.*["\']', content):
                                    patterns["sql_injection_risk"].append(file_path)
                                
                                # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ XSS
                                if re.search(r'innerHTML\s*=', content):
                                    patterns["xss_risk"].append(file_path)
                                    
                            except Exception:
                                continue
        
        return patterns
    
    def _check_data_safety(self) -> Dict[str, Any]:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏ –¥–∞–Ω–Ω—ã—Ö"""
        safety_checks = {
            "input_validation": False,
            "output_sanitization": False,
            "error_handling": False,
            "logging_safety": False
        }
        
        source_dirs = self.config.get('source_dirs', ['src/'])
        for source_dir in source_dirs:
            if os.path.exists(source_dir):
                for root, dirs, files in os.walk(source_dir):
                    for file in files:
                        if file.endswith(('.py', '.ts', '.tsx', '.js', '.jsx')):
                            file_path = os.path.join(root, file)
                            try:
                                with open(file_path, 'r', encoding='utf-8') as f:
                                    content = f.read()
                                
                                # –ü—Ä–æ–≤–µ—Ä–∫–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
                                if any(keyword in content.lower() for keyword in ['validate', 'sanitize', 'check']):
                                    safety_checks["input_validation"] = True
                                
                                # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–∞–Ω–∏—Ç–∏–∑–∞—Ü–∏–∏ –≤—ã–≤–æ–¥–∞
                                if any(keyword in content.lower() for keyword in ['escape', 'encode', 'sanitize']):
                                    safety_checks["output_sanitization"] = True
                                
                                # –ü—Ä–æ–≤–µ—Ä–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –æ—à–∏–±–æ–∫
                                if any(keyword in content.lower() for keyword in ['try:', 'except:', 'catch', 'error']):
                                    safety_checks["error_handling"] = True
                                
                                # –ü—Ä–æ–≤–µ—Ä–∫–∞ –±–µ–∑–æ–ø–∞—Å–Ω–æ–≥–æ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
                                if 'log' in content.lower() and 'password' not in content.lower():
                                    safety_checks["logging_safety"] = True
                                    
                            except Exception:
                                continue
        
        return safety_checks
    
    def _calculate_code_ethics_score(self, ethics_mentions: Dict, problematic_patterns: Dict, data_safety: Dict) -> float:
        """–†–∞—Å—á—ë—Ç –æ—Ü–µ–Ω–∫–∏ —ç—Ç–∏—á–Ω–æ—Å—Ç–∏ –∫–æ–¥–∞"""
        # –ë–∞–∑–æ–≤—ã–π –±–∞–ª–ª
        score = 0.5
        
        # –ë–æ–Ω—É—Å—ã –∑–∞ —É–ø–æ–º–∏–Ω–∞–Ω–∏—è —ç—Ç–∏–∫–∏
        total_mentions = sum(ethics_mentions.values())
        if total_mentions > 0:
            score += min(total_mentions * 0.1, 0.3)
        
        # –®—Ç—Ä–∞—Ñ—ã –∑–∞ –ø—Ä–æ–±–ª–µ–º–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã
        total_problems = sum(len(patterns) for patterns in problematic_patterns.values())
        if total_problems > 0:
            score -= min(total_problems * 0.05, 0.4)
        
        # –ë–æ–Ω—É—Å—ã –∑–∞ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å –¥–∞–Ω–Ω—ã—Ö
        safety_bonus = sum(1 for check in data_safety.values() if check) * 0.1
        score += min(safety_bonus, 0.2)
        
        return max(0.0, min(score, 1.0))
    
    def _audit_configuration(self) -> Dict[str, Any]:
        """–ê—É–¥–∏—Ç –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –Ω–∞ —ç—Ç–∏—á–µ—Å–∫–∏–µ –∞—Å–ø–µ–∫—Ç—ã"""
        config_ethics = {
            "governance_enabled": self.config.get('governance_audit', {}).get('enabled', False),
            "security_enabled": self.config.get('security_audit', {}).get('enabled', False),
            "cognitive_audit_enabled": self.config.get('cognitive_audit', {}).get('enabled', False),
            "transparency_settings": self._check_transparency_settings(),
            "privacy_settings": self._check_privacy_settings()
        }
        
        return config_ethics
    
    def _check_transparency_settings(self) -> Dict[str, bool]:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞—Å—Ç—Ä–æ–µ–∫ –ø—Ä–æ–∑—Ä–∞—á–Ω–æ—Å—Ç–∏"""
        return {
            "audit_logging": True,  # –ü—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ–º, —á—Ç–æ –∞—É–¥–∏—Ç –≤–∫–ª—é—á—ë–Ω
            "metrics_exposure": True,  # –ú–µ—Ç—Ä–∏–∫–∏ –¥–æ—Å—Ç—É–ø–Ω—ã —á–µ—Ä–µ–∑ API
            "error_reporting": True,  # –û—à–∏–±–∫–∏ –ª–æ–≥–∏—Ä—É—é—Ç—Å—è
            "decision_tracking": False  # –ù—É–∂–Ω–æ –ø—Ä–æ–≤–µ—Ä–∏—Ç—å –Ω–∞–ª–∏—á–∏–µ —Ç—Ä–µ–∫–∏–Ω–≥–∞ —Ä–µ—à–µ–Ω–∏–π
        }
    
    def _check_privacy_settings(self) -> Dict[str, bool]:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞—Å—Ç—Ä–æ–µ–∫ –ø—Ä–∏–≤–∞—Ç–Ω–æ—Å—Ç–∏"""
        return {
            "data_encryption": False,  # –ù—É–∂–Ω–æ –ø—Ä–æ–≤–µ—Ä–∏—Ç—å –Ω–∞–ª–∏—á–∏–µ —à–∏—Ñ—Ä–æ–≤–∞–Ω–∏—è
            "access_control": True,  # –ü—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ–º –Ω–∞–ª–∏—á–∏–µ –∫–æ–Ω—Ç—Ä–æ–ª—è –¥–æ—Å—Ç—É–ø–∞
            "data_retention": True,  # –ï—Å—Ç—å –∂—É—Ä–Ω–∞–ª —Å –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ–º –∑–∞–ø–∏—Å–µ–π
            "anonymization": False  # –ù—É–∂–Ω–æ –ø—Ä–æ–≤–µ—Ä–∏—Ç—å –∞–Ω–æ–Ω–∏–º–∏–∑–∞—Ü–∏—é –¥–∞–Ω–Ω—ã—Ö
        }
    
    def _audit_privacy(self) -> Dict[str, Any]:
        """–ê—É–¥–∏—Ç –ø—Ä–∏–≤–∞—Ç–Ω–æ—Å—Ç–∏ –∏ –∑–∞—â–∏—Ç—ã –¥–∞–Ω–Ω—ã—Ö"""
        privacy_audit = {
            "data_collection": self._analyze_data_collection(),
            "data_storage": self._analyze_data_storage(),
            "data_sharing": self._analyze_data_sharing(),
            "user_consent": self._check_user_consent()
        }
        
        return privacy_audit
    
    def _analyze_data_collection(self) -> Dict[str, Any]:
        """–ê–Ω–∞–ª–∏–∑ —Å–±–æ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö"""
        return {
            "minimal_collection": True,  # –°–æ–±–∏—Ä–∞–µ–º —Ç–æ–ª—å–∫–æ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –º–µ—Ç—Ä–∏–∫–∏
            "purpose_limitation": True,  # –î–∞–Ω–Ω—ã–µ –∏—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Å–∏—Å—Ç–µ–º—ã
            "data_types": ["metrics", "logs", "performance_data"],
            "collection_frequency": "real_time"
        }
    
    def _analyze_data_storage(self) -> Dict[str, Any]:
        """–ê–Ω–∞–ª–∏–∑ —Ö—Ä–∞–Ω–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö"""
        return {
            "local_storage": True,  # –î–∞–Ω–Ω—ã–µ —Ö—Ä–∞–Ω—è—Ç—Å—è –ª–æ–∫–∞–ª—å–Ω–æ
            "retention_policy": "rolling_window",  # Rolling window –¥–ª—è –∂—É—Ä–Ω–∞–ª–∞
            "encryption": False,  # –ù—É–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å —à–∏—Ñ—Ä–æ–≤–∞–Ω–∏–µ
            "backup_strategy": "none"  # –ù–µ—Ç —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ —Ä–µ–∑–µ—Ä–≤–Ω–æ–≥–æ –∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∏—è
        }
    
    def _analyze_data_sharing(self) -> Dict[str, Any]:
        """–ê–Ω–∞–ª–∏–∑ –æ–±–º–µ–Ω–∞ –¥–∞–Ω–Ω—ã–º–∏"""
        return {
            "third_party_sharing": False,  # –î–∞–Ω–Ω—ã–µ –Ω–µ –ø–µ—Ä–µ–¥–∞—é—Ç—Å—è —Ç—Ä–µ—Ç—å–∏–º –ª–∏—Ü–∞–º
            "api_exposure": True,  # API –¥–æ—Å—Ç—É–ø–µ–Ω –¥–ª—è –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞
            "data_export": False,  # –ù–µ—Ç —ç–∫—Å–ø–æ—Ä—Ç–∞ –¥–∞–Ω–Ω—ã—Ö
            "anonymization": False  # –ù–µ—Ç –∞–Ω–æ–Ω–∏–º–∏–∑–∞—Ü–∏–∏
        }
    
    def _check_user_consent(self) -> Dict[str, Any]:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ–≥–ª–∞—Å–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è"""
        return {
            "consent_mechanism": False,  # –ù–µ—Ç –º–µ—Ö–∞–Ω–∏–∑–º–∞ —Å–æ–≥–ª–∞—Å–∏—è
            "opt_out_option": False,  # –ù–µ—Ç –æ–ø—Ü–∏–∏ –æ—Ç–∫–∞–∑–∞
            "privacy_notice": False,  # –ù–µ—Ç —É–≤–µ–¥–æ–º–ª–µ–Ω–∏—è –æ –ø—Ä–∏–≤–∞—Ç–Ω–æ—Å—Ç–∏
            "data_subject_rights": False  # –ù–µ—Ç –ø—Ä–∞–≤ —Å—É–±—ä–µ–∫—Ç–æ–≤ –¥–∞–Ω–Ω—ã—Ö
        }
    
    def _calculate_ethical_score(self, doc_audit: Dict, code_audit: Dict, 
                               config_audit: Dict, privacy_audit: Dict) -> float:
        """–†–∞—Å—á—ë—Ç –æ–±—â–µ–π —ç—Ç–∏—á–µ—Å–∫–æ–π –æ—Ü–µ–Ω–∫–∏"""
        # –í–µ—Å–∞ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
        weights = {
            'documentation': 0.25,
            'code': 0.35,
            'configuration': 0.2,
            'privacy': 0.2
        }
        
        # –û—Ü–µ–Ω–∫–∏ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
        doc_score = doc_audit.get('documentation_score', 0.0)
        code_score = code_audit.get('overall_code_ethics_score', 0.0)
        config_score = sum(1 for v in config_audit.values() if v) / len(config_audit) if config_audit else 0.0
        privacy_score = self._calculate_privacy_score(privacy_audit)
        
        # –í–∑–≤–µ—à–µ–Ω–Ω–∞—è —Å—É–º–º–∞
        overall_score = (
            doc_score * weights['documentation'] +
            code_score * weights['code'] +
            config_score * weights['configuration'] +
            privacy_score * weights['privacy']
        )
        
        return min(overall_score, 1.0)
    
    def _calculate_privacy_score(self, privacy_audit: Dict) -> float:
        """–†–∞—Å—á—ë—Ç –æ—Ü–µ–Ω–∫–∏ –ø—Ä–∏–≤–∞—Ç–Ω–æ—Å—Ç–∏"""
        scores = []
        
        # –û—Ü–µ–Ω–∫–∞ —Å–±–æ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö
        data_collection = privacy_audit.get('data_collection', {})
        if data_collection.get('minimal_collection') and data_collection.get('purpose_limitation'):
            scores.append(0.8)
        else:
            scores.append(0.4)
        
        # –û—Ü–µ–Ω–∫–∞ —Ö—Ä–∞–Ω–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö
        data_storage = privacy_audit.get('data_storage', {})
        if data_storage.get('local_storage') and data_storage.get('retention_policy'):
            scores.append(0.6)
        else:
            scores.append(0.3)
        
        # –û—Ü–µ–Ω–∫–∞ –æ–±–º–µ–Ω–∞ –¥–∞–Ω–Ω—ã–º–∏
        data_sharing = privacy_audit.get('data_sharing', {})
        if not data_sharing.get('third_party_sharing'):
            scores.append(0.7)
        else:
            scores.append(0.2)
        
        return sum(scores) / len(scores) if scores else 0.0
    
    def _classify_ethical_status(self, score: float) -> str:
        """–ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è —ç—Ç–∏—á–µ—Å–∫–æ–≥–æ —Å—Ç–∞—Ç—É—Å–∞"""
        if score >= 0.8:
            return "excellent"
        elif score >= 0.6:
            return "good"
        elif score >= 0.4:
            return "fair"
        else:
            return "poor"
    
    def _generate_ethical_recommendations(self, doc_audit: Dict, code_audit: Dict,
                                        config_audit: Dict, privacy_audit: Dict) -> List[str]:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —ç—Ç–∏—á–µ—Å–∫–∏—Ö —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π"""
        recommendations = []
        
        # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏
        if doc_audit.get('documentation_score', 0) < 0.5:
            recommendations.append("üìö –£–ª—É—á—à–∏—Ç–µ —ç—Ç–∏—á–µ—Å–∫—É—é –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—é: –¥–æ–±–∞–≤—å—Ç–µ –ø–æ–ª–∏—Ç–∏–∫–∏ –ø—Ä–∏–≤–∞—Ç–Ω–æ—Å—Ç–∏ –∏ —ç—Ç–∏—á–µ—Å–∫–∏–µ –ø—Ä–∏–Ω—Ü–∏–ø—ã")
        
        # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –∫–æ–¥—É
        if code_audit.get('overall_code_ethics_score', 0) < 0.6:
            recommendations.append("üíª –£–ª—É—á—à–∏—Ç–µ —ç—Ç–∏—á–Ω–æ—Å—Ç—å –∫–æ–¥–∞: –¥–æ–±–∞–≤—å—Ç–µ –≤–∞–ª–∏–¥–∞—Ü–∏—é –¥–∞–Ω–Ω—ã—Ö –∏ –æ–±—Ä–∞–±–æ—Ç–∫—É –æ—à–∏–±–æ–∫")
        
        # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
        if not config_audit.get('governance_enabled', False):
            recommendations.append("‚öôÔ∏è –í–∫–ª—é—á–∏—Ç–µ —É–ø—Ä–∞–≤–ª–µ–Ω—á–µ—Å–∫–∏–π –∞—É–¥–∏—Ç –≤ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏")
        
        # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –ø—Ä–∏–≤–∞—Ç–Ω–æ—Å—Ç–∏
        if not privacy_audit.get('data_storage', {}).get('encryption', False):
            recommendations.append("üîí –î–æ–±–∞–≤—å—Ç–µ —à–∏—Ñ—Ä–æ–≤–∞–Ω–∏–µ –¥–ª—è –∑–∞—â–∏—Ç—ã –¥–∞–Ω–Ω—ã—Ö")
        
        if not privacy_audit.get('user_consent', {}).get('consent_mechanism', False):
            recommendations.append("üë§ –†–µ–∞–ª–∏–∑—É–π—Ç–µ –º–µ—Ö–∞–Ω–∏–∑–º —Å–æ–≥–ª–∞—Å–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è")
        
        if not recommendations:
            recommendations.append("‚úÖ –≠—Ç–∏—á–µ—Å–∫–æ–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –Ω–∞ —Ö–æ—Ä–æ—à–µ–º —É—Ä–æ–≤–Ω–µ, –ø—Ä–æ–¥–æ–ª–∂–∞–π—Ç–µ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥")
        
        return recommendations

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –∑–∞–ø—É—Å–∫–∞ —ç—Ç–∏—á–µ—Å–∫–æ–≥–æ –∞—É–¥–∏—Ç–∞"""
    import argparse
    
    parser = argparse.ArgumentParser(description='–≠—Ç–∏—á–µ—Å–∫–∏–π –∞—É–¥–∏—Ç TERAG AI-REPS')
    parser.add_argument('--output', '-o', help='–ü—É—Ç—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –æ—Ç—á—ë—Ç–∞')
    parser.add_argument('--config', '-c', default='.auditconfig.yaml', help='–ü—É—Ç—å –∫ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏')
    
    args = parser.parse_args()
    
    auditor = EthicsAuditor(args.config)
    result = auditor.evaluate_ethical_compliance()
    
    if args.output:
        with open(args.output, 'w', encoding='utf-8') as f:
            json.dump(result, f, indent=2, ensure_ascii=False)
    else:
        print(json.dumps(result, indent=2, ensure_ascii=False))

if __name__ == "__main__":
    main()
