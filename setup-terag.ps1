# üöÄ TERAG Automated Setup Script for Cursor IDE
# –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –Ω–∞—Å—Ç—Ä–æ–π–∫–∞ –≤—Å–µ–π –∏–Ω—Ñ—Ä–∞—Å—Ç—Ä—É–∫—Ç—É—Ä—ã TERAG

param(
    [string]$ProjectPath = ".",
    [switch]$SkipNeo4j = $false,
    [switch]$Force = $false
)

Write-Host "üöÄ TERAG Automated Setup Script" -ForegroundColor Cyan
Write-Host "=================================" -ForegroundColor Cyan
Write-Host ""

# 1Ô∏è‚É£ –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ä–µ–¥—ã
Write-Host "1Ô∏è‚É£ Checking environment..." -ForegroundColor Yellow

# –ü—Ä–æ–≤–µ—Ä—è–µ–º Ollama
try {
    $ollamaVersion = ollama --version 2>$null
    if ($ollamaVersion) {
        Write-Host "‚úÖ Ollama: $ollamaVersion" -ForegroundColor Green
    } else {
        Write-Host "‚ùå Ollama not found. Please install from https://ollama.ai" -ForegroundColor Red
        exit 1
    }
} catch {
    Write-Host "‚ùå Ollama not found. Please install from https://ollama.ai" -ForegroundColor Red
    exit 1
}

# –ü—Ä–æ–≤–µ—Ä—è–µ–º Python
try {
    $pythonVersion = python --version 2>$null
    if ($pythonVersion -match "Python (\d+)\.(\d+)") {
        $major = [int]$matches[1]
        $minor = [int]$matches[2]
        if ($major -ge 3 -and $minor -ge 10) {
            Write-Host "‚úÖ Python: $pythonVersion" -ForegroundColor Green
        } else {
            Write-Host "‚ùå Python version too old: $pythonVersion (need 3.10+)" -ForegroundColor Red
            exit 1
        }
    }
} catch {
    Write-Host "‚ùå Python not found. Please install from https://python.org" -ForegroundColor Red
    exit 1
}

Write-Host ""

# 2Ô∏è‚É£ –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π Python
Write-Host "2Ô∏è‚É£ Installing Python dependencies..." -ForegroundColor Yellow

$packages = @(
    "chromadb",
    "langchain", 
    "langchain-community",
    "ragas",
    "fastapi",
    "uvicorn",
    "neo4j",
    "networkx",
    "pyvis",
    "loguru"
)

foreach ($package in $packages) {
    Write-Host "Installing $package..." -ForegroundColor Gray
    pip install $package --quiet
    if ($LASTEXITCODE -eq 0) {
        Write-Host "‚úÖ $package installed" -ForegroundColor Green
    } else {
        Write-Host "‚ùå Failed to install $package" -ForegroundColor Red
    }
}

Write-Host ""

# 3Ô∏è‚É£ –°–æ–∑–¥–∞–Ω–∏–µ –∏–Ω–¥–µ–∫—Å–∞—Ç–æ—Ä–∞ –∫–æ–¥–∞
Write-Host "3Ô∏è‚É£ Creating code indexer..." -ForegroundColor Yellow

$indexerCode = @"
from langchain_community.vectorstores import Chroma
from langchain_community.document_loaders import DirectoryLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.embeddings import OllamaEmbeddings
import os
import argparse

def index_repository(repo_path):
    print(f"Indexing repository: {repo_path}")
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –≤—Å–µ —Ñ–∞–π–ª—ã –ø—Ä–æ–µ–∫—Ç–∞
    loader = DirectoryLoader(repo_path, glob="**/*.{py,ts,tsx,js,jsx,md,json}")
    docs = loader.load()
    print(f"Loaded {len(docs)} documents")
    
    # –†–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ —á–∞–Ω–∫–∏
    splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
    texts = splitter.split_documents(docs)
    print(f"Split into {len(texts)} chunks")
    
    # –°–æ–∑–¥–∞—ë–º —ç–º–±–µ–¥–¥–∏–Ω–≥–∏
    embeddings = OllamaEmbeddings(model="nomic-embed-text")
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ ChromaDB
    db = Chroma.from_documents(texts, embeddings, persist_directory="./chroma_store")
    db.persist()
    print("‚úÖ Indexing completed successfully!")

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="Index codebase for RAG")
    parser.add_argument("--path", default=".", help="Path to repository")
    args = parser.parse_args()
    
    index_repository(args.path)
"@

$indexerCode | Out-File -FilePath "index_codebase.py" -Encoding UTF8
Write-Host "‚úÖ Created index_codebase.py" -ForegroundColor Green

# 4Ô∏è‚É£ –°–æ–∑–¥–∞–Ω–∏–µ RAG-–∑–∞–ø—Ä–æ—Å–Ω–∏–∫–∞
Write-Host "4Ô∏è‚É£ Creating RAG query interface..." -ForegroundColor Yellow

$ragCode = @"
from langchain_community.vectorstores import Chroma
from langchain.chains import RetrievalQA
from langchain.llms import Ollama
import argparse

def ask(query):
    print(f"Query: {query}")
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º LLM
    llm = Ollama(model="deepseek-coder:6.7b")
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö
    db = Chroma(persist_directory="./chroma_store", embedding_function=None)
    retriever = db.as_retriever(search_kwargs={"k": 5})
    
    # –°–æ–∑–¥–∞—ë–º QA —Ü–µ–ø–æ—á–∫—É
    qa = RetrievalQA.from_chain_type(llm, chain_type="stuff", retriever=retriever)
    
    # –í—ã–ø–æ–ª–Ω—è–µ–º –∑–∞–ø—Ä–æ—Å
    result = qa.run(query)
    print(f"Answer: {result}")

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="Query RAG database")
    parser.add_argument("query", nargs="?", help="Query to ask")
    args = parser.parse_args()
    
    if args.query:
        ask(args.query)
    else:
        query = input("Enter your question: ")
        ask(query)
"@

$ragCode | Out-File -FilePath "ask_rag.py" -Encoding UTF8
Write-Host "‚úÖ Created ask_rag.py" -ForegroundColor Green

# 5Ô∏è‚É£ –°–æ–∑–¥–∞–Ω–∏–µ .env —Ñ–∞–π–ª–∞
Write-Host "5Ô∏è‚É£ Creating environment configuration..." -ForegroundColor Yellow

$envContent = @"
# TERAG Environment Configuration
NEO4J_URI=bolt://localhost:7687
NEO4J_USER=neo4j
NEO4J_PASSWORD=12345

# Ollama Configuration
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=deepseek-coder:6.7b

# RAG Configuration
CHROMA_PERSIST_DIRECTORY=./chroma_store
EMBEDDING_MODEL=nomic-embed-text
"@

$envContent | Out-File -FilePath ".env" -Encoding UTF8
Write-Host "‚úÖ Created .env file" -ForegroundColor Green

# 6Ô∏è‚É£ –ò–Ω–¥–µ–∫—Å–∞—Ü–∏—è –ø—Ä–æ–µ–∫—Ç–∞
Write-Host "6Ô∏è‚É£ Indexing project..." -ForegroundColor Yellow

python index_codebase.py --path $ProjectPath
if ($LASTEXITCODE -eq 0) {
    Write-Host "‚úÖ Project indexed successfully!" -ForegroundColor Green
} else {
    Write-Host "‚ùå Indexing failed" -ForegroundColor Red
}

Write-Host ""

# 7Ô∏è‚É£ –°–æ–∑–¥–∞–Ω–∏–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ Cursor
Write-Host "7Ô∏è‚É£ Creating Cursor configuration..." -ForegroundColor Yellow

$cursorConfig = @{
    "cursor_ai_models" = @{
        "local_ollama" = @{
            "provider" = "openai"
            "model" = "deepseek-coder"
            "baseURL" = "http://localhost:11434/v1"
            "apiKey" = "ollama"
            "description" = "DeepSeek Coder (Local via Ollama)"
        }
    }
    "mcp_servers" = @{
        "local_rag" = @{
            "name" = "local_rag"
            "command" = "python"
            "args" = @("ask_rag.py")
            "type" = "local"
            "description" = "Local RAG search for codebase"
        }
    }
    "workspace_settings" = @{
        "ai.model" = "local_ollama"
        "ai.enableCodeActions" = $true
        "ai.enableChat" = $true
        "ai.enableCompletions" = $true
    }
}

$cursorConfig | ConvertTo-Json -Depth 3 | Out-File -FilePath "cursor_config.json" -Encoding UTF8
Write-Host "‚úÖ Created cursor_config.json" -ForegroundColor Green

# 8Ô∏è‚É£ –°–æ–∑–¥–∞–Ω–∏–µ README —Å –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è–º–∏
Write-Host "8Ô∏è‚É£ Creating setup instructions..." -ForegroundColor Yellow

$readmeContent = @"
# üöÄ TERAG Setup Complete!

## ‚úÖ What's Ready

- **Ollama Runtime**: Connected to local models
- **RAG Service**: Project indexed and ready
- **Python Environment**: All dependencies installed
- **Cursor Configuration**: Ready for integration

## üîß Manual Steps in Cursor IDE

### 1. Add AI Model
1. Open Cursor Settings (Ctrl+,)
2. Go to AI Models ‚Üí Add Custom Model
3. Fill in:
   - Provider: OpenAI
   - Base URL: http://localhost:11434/v1
   - API Key: ollama

### 2. Add MCP Server
1. Go to Settings ‚Üí MCP Servers ‚Üí Add Server
2. Fill in:
   - Name: local_rag
   - Command: python
   - Args: ask_rag.py

## üß™ Testing

\`\`\`bash
# Test RAG search
python ask_rag.py "Where is loadGraph function implemented?"

# Test with specific query
python ask_rag.py "How does the voice mode work?"
\`\`\`

## üéØ Usage in Cursor

Once configured, you can use in Cursor:
- \`@local_rag search "your query"\`
- \`@local_rag search --function loadGraph\`

## üîÑ Updating Index

When code changes:
\`\`\`bash
python index_codebase.py --path .
\`\`\`

---
**Setup completed successfully!** üéâ
"@

$readmeContent | Out-File -FilePath "TERAG_SETUP_COMPLETE.md" -Encoding UTF8
Write-Host "‚úÖ Created TERAG_SETUP_COMPLETE.md" -ForegroundColor Green

Write-Host ""
Write-Host "üéâ SETUP COMPLETED SUCCESSFULLY!" -ForegroundColor Green
Write-Host "=================================" -ForegroundColor Green
Write-Host ""
Write-Host "Next steps:" -ForegroundColor Cyan
Write-Host "1. Open Cursor IDE" -ForegroundColor White
Write-Host "2. Configure AI Models and MCP Servers (see TERAG_SETUP_COMPLETE.md)" -ForegroundColor White
Write-Host "3. Test with: python ask_rag.py 'your query'" -ForegroundColor White
Write-Host ""
Write-Host "Ready to code with local AI! üöÄ" -ForegroundColor Green
